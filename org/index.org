#+TITLE:    zotherstupidguy log 
#+AUTHOR:    Mohamed Fouad
#+EMAIL:     zotherstupidguy@gmail.com
#+DESCRIPTION: daily log of zotherstupidguy life 
#+KEYWORDS:  emacs, mathematics, computer science, machine learning 
#+LANGUAGE:  en
#+STYLE:body {font-family: "Source Sans Pro Black",sans-serif;}
#+OPTIONS: H:3 num:0
#+TAGS: zpd0(0)  zpd1(1) zpd2(2)  problem solution predicate implication question fig mindmap number_theory set_theory proof_theory computational_theory problem_solving category_theory single_variable_calculas multi_variable_calculas vedic_mathematics graph_theory discerete_mathematics concerete_mathematics continous_mathematics statistics real_analysis grit top_universities studying_strategy data_structures algorithms artificial_intellegence machine_learning deep_learning bigdata R python puzzles { MOOC : coursera  stanford oxford MIT} { philosphy : socrates plato} book youtube blog competitive_programming C_programming  {algorithms : ConstructiveAlgorithms Strings Sorting Search GraphTheory Greedy  DynamicProgramming  BitManipulation  Recursion  GameTheory  NPComplete } DistributedSystems Regex Security Functions Cryptography


* About
  Hello, I am Mohamed Fouad a.k.a zotherstupidguy, a Software Philosopher living in Alexandria, Egypt; and this is my day-to-day b(log). 
  I am available for [hire [link to google docs resume]].
  This is an org-mode generated log (Org-Agenda, Org-Capture, tag-based organization) via those [[https://github.com/zotherstupidguy/dotfiles][dotfiles]] 
  and acutal [[https://github.com/zotherstupidguy/zotherstupidguy.github.io][source]] of this blog. 
  
  -----

  Why zotherstupidguy nick? it is a joke and a reminder that being smart is totally relevant to my current knowledge circles,
  and I must always seek ideas outside of my regular knowledge circles, anything that I am already familair with probably wouldn't breed me 
  an *orginal* idea, I must seek doctrine depth through skeptic breadths!

  -----
  
  *As lazy as I am*, I plan using the notes here *to cheat at phone interviews*, 
  Emacs got a nice regex search ;) IF YOU BELONG TO THE SET OF THE FEW PEOPLE 
  ON EARTH WHO READ MY BLOG *AND* ACTUALLY PLAN TO HIRE ME, 
  PLEASE LET ME KNOW IF YOU THINK I AM FUNNY.

  -----
  Once in a while, I examine how Top Universities offer their mathematics and computer science related programs. I try to find what kind of books they set as 
  textbooks, to go read them on my own, purchase them from Amazon (I only like *Hardcover* books!), or scout them in the cheap 2nd hand street book markets. 
  My act is inspired by *“You wasted $150,000 on an education you coulda got for $1.50 in late fees at the public library.” ― Matt Damon, Good Will Hunting*. 
  I worship those Professors who offer their courses online for free! If it is up to me I build them real-size human sculptures in my City. 
  *Knoweldge belong to all mankind, not to copyright owners who suffer from financial insecurities!*
  ----- 
  Public keys(if you wish to communicate with me securely)
  
  ----- 

** Funny Thoughts
   Ancient Egyptians had n gods, as each person was so focused into their profession that they created a God for this body of knoweldge to 
   worship day and night. If computer science folks would do the same, they would create Knuth God, after Donald Knuth :D

** Companies I would like to work for
   - Thoughtbot
   - Github
   - Google
   - Amazon
   - Thoughtworks
   - Gitlab
   - Facebook
   - Twitter
   - Hackerrank
   ----- 
** Why should we hire you?
   Because AI is not that good "yet", and you and I still need other humans to survive!
** Grit :: Perseverance and Passion for Long-term Goals 
   :PROPERTIES:
   :DESCRIPTION: Must have Personal Traits via continous conditioning
   :CATEGORY: research
   :ZPT:      0
   :END:
   + Courage
     - understand that there are valuable lessons in defeat and that the vulnerability of perseverance is requisite for high achievement.  
     - 
     - 
   -----

** Studying Strategy 
   My study strategy says that each book, videocourse, etc. is in one direcotry. This is my study log, I keep all the 
   knowledge that I aquire into this file, and I organize it accordingly to smallest possible domain of knowledge such as instead of having
   a heading for Number Theory, I have multiple headings for topics such as Prime Numbers, that way when I read a book I don't read the chapters but
   I explore the glossry and find where my objective topic exists and I write it down based on:  
   - why is it worth the effort?
   - what should be persued? 
   - how it will be persued?

*** Cornell Note Taking System & Feynman Technique
    I employ the Feynman technique in the Reviewing stage of my SQ3R 

    Refs: 
    - Learn Faster with The Feynman Technique
    https://www.youtube.com/watch?v=FrNqSLPaZLc

    - How to Learn Faster with the Feynman Technique:  
    https://www.youtube.com/watch?v=_f-qkGJBPts


*** Finding Sources
    using ./link to automatically download new youtube videos and generate an RSS of it and update log.org with a TODO for watching new things.
    I can't add ZPT, can, and can't folders in the sources folders as it will make ./link difficult to know what already got downloaded.


    ----- 

** Training Strategy
   The main idea of Competitive Programming Training is to solve any given problem in under 10minutes, thus the 
   most basic studytime unit  is t = 10mins, henceforth all my study and practice activites are divided up in units of 10mins.

   I categorieze my incoming infromation into 3 categories: 
   A. Can,    12 problems, total 12t(2hrs)
   B. ZPD,    4 problems, total 12t(2hrs)
   C. Can't.  1 problem, total 12t(2hrs)

** ZotherZPD(Zone of Proximal Development) Index
   - Can't is *0  =  ZPD0, thus I name respective headings with :zpd0:
   - ZPD is *1    = ZPD1, thus I name respective headings with :zpd1;
   - Can is *2    = ZPD2, thus I name respective headings with :zpd2:
     According to this index I can *automatically* calculate (via emacs) 
   a score * 0 or * 1 or * 2 / by the number of shit I am trying to accomplish.


   I start my day trying to attack category *C. Can't* to fail and study a bit, 
   then go for the *B.ZPD* which is my zone of proximal development, 
   with some effort I can succeed in solving a problem in 30mins.
   then I end my day with the *A.can* somthing that I solved before or know I can solve. 
   Simple Objectives results in Simple Delights makes me happy at the end of the day. 

   After Studying or Practice, blog about it using the Feynman Technique,  

   All problems are solved in C with emacs templates to save time.

   In order to achieve that training is divided into 3 difficulity/time categories: ZPT0, ZPT1, ZPT2.
   - 2hrs for *one* ZPT0 problem, this is a problem that are too difficult to solve and requires significant studying  
   to be familiar with the nessesary knowledge domain(s), 
     the 2hours are dedicated for 
     - Understanding the problem
     - Identifying which knowledge domain(s) it belongs to.
     - Reading about those knowledge domain(s).
     - Attempt to provide a solution  
     - 2hrs for *up to 4* ZPT1 problems, those are problems that their solutions depends on knowledge domain(s) 
     that I am already familiar with. 
     - 2hrs for *up to 12* ZPT2 problems, those are probems that I solved in the past one time or more and 
     I need to enhance my speed in solving them.


   ----- 

** Publish it! 
   Naturally I could write a book or two from the notes I have written into this file. As a matter of fact, I belive that
   *the only way* computer scientets are capable of writing so many powerful books is due to the fact that they use
   emacs in a similar way to what I am doing here, I can collect information and tag it, search it easily and update it,
   check cross references, etc. *It feels Awesome to be that Powerful!* I think i will keep taking notes in notebooks and as a review, I 
   will transfer the notes to this org document. I expect to be able to have codeblocks, latex formulas and maybe even 
   graphs. Eventually I shall publish a series about computer science via https://leanpub.com, call it "zotherstupidguy computer science notes" 
   each volume is small 100pages book of notes and commentary. 

** Brain Waves
   Each of us can use brainwave entrainment to achieve a variety of results. 
   You may want to target a specific brainwave frequency range to help you relax,. 
   On the other hand you may want to increase you creative energy, improve your memory, 
   deepen your sleep or get better results when playing a sport.
*** Beta brainwaves
    (14 to 32 Hz alert, focused)
    Beta is the most common brain wave pattern: Beta brainwaves are produced when we are wide awake, alert, 
    active and engaged in mental activity, usually involving more the rational, reality-oriented left hemisphere of our brain. 
    When beta wave activity becomes very intense, our brain hemispheres become less synchronized. 
    Beta state is required to function properly in your everyday life.
**** Features and Benefits of a Beta State
     - This is the brainwave for the fight-flight response
     - Increased concentration and alertness
     - Improved logic, reasoning and critical thinking
     - Feelings of anxiety, stress, scatty unfocused thought
     NOTE: Excessive Beta brainwaves are also a feature of insomnia
 
*** Alpha brainwaves
    (7 to 14 Hz relaxed yet aware, meditative)
    These are lower frequency waves: The state is generated when our thoughts are really not concentrated and our minds wonder freely, 
    or we are in a relaxed state such as meditating or daydreaming. We also experience Alpha Brainwaves when we are gently busy i
    with routine tasks like pottering in the garden, taking a shower, putting on makeup, doing light housework. 
    Alpha is considered to be the bridge between the conscious mind and the subconscious mind.

**** Features and Benefits of an Alpha State
     - Our brain hemispheres become naturally synchronized, or in-phase with each other.
     - Relaxed detached (absent-minded) awareness and daydreaming mind.
     - Enables us to remember our dreams and meditative states.
     - Link between conscious and subconscious mind, gateway to meditation.
     - Receptive to casual and auto – suggestions (hypnosis state)
     - Increased vividness benefits creative visualization and triggers imagination
     - Increased  memory retention , concentration & focus for super learning
**** Health benefits include:
     - Reduced anxiety
     - Alleviates stress and depression
     - Reduces chronic pain
     - Reduction of high blood pressure
     - Increases athletic performance
     - Increased  cerebral blood flow
     - Increased motivation, energy, and happiness

*** Theta brainwaves
    (3.5 to 7 Hz deep relaxation, twilight state)
    Theta brainwave states have been used in meditation for centuries: It is common for people to feel as if they are in a trance, 
    where the mind feels as though it may have gone to sleep although it is conscious of what is happening around it. 
    Theta induces a capacity for prolonged daydreaming, where a loss of time may be experienced.
    Theta waves are also conducive to visualization and creativity and the mind in this very relaxed state is highly receptive to direct suggestion under hypnosis. As with Alpha, in Theta our brain hemispheres are synchronized and we experience whole brain functioning.

**** Features and benefits of Theta brainwaves
     - Increased sense of inner peace and emotional stability
     - Deep relaxation
     - Improved memory
     - Heightened intuition and inspiration
     - Calms the chatter of your mind
     - Increased psychic abilities and sense of spiritual connection
     - Health benefits of Theta brainwaves
     - Speed healing, improved physical healing
     - Sleep onset and better more restful sleep
     - Release beneficial hormones related to health and longevity
     - Reduce mental fatigue
     - Reduction of anxiety and stress
     NOTE: Research has proven thirty minutes a day of Theta meditation can dramatically improve a person’s overall health and well-being. Theta meditation has also been known to result in a reduced need for sleep.
 
*** Delta brainwaves
    (0.1 to 3.5 Hz deep sleep )
    This is the slowest band of waves that our brains produce and they occur when we are in deep, dreamless sleep. 
    These waves are very beneficial for the body which restores and heals itself when in this state. 
    The delta state releases anti-aging hormones, including melatonin and DHEA. 
    Human growth hormone (HGH) is another anti-aging hormone that is increased when delta brainwaves are occurring inside the brain, 
    due to the stimulation of the pituitary gland. HGH maintains the skin, bone density, cartilage, and the joints in your body as 
    well as speeds up the healing process of joint and cartilage injuries. HGH can also help heal physical pain.

    In healthy amounts, delta brainwaves can also cause a person to have an advanced state of empathy, understanding, and compassion for others.
    Delta is the place of deepest relaxation, deepest healing, deepest spiritual connection and deepest connection with the subconscious mind. 
    It is considered to be the gateway to the unconscious mind and the collective unconscious, bringing access to the universal psyche or mind.
 
*** Gamma brainwaves
    (40Hz or higher: zen mind mastery)
    Gamma brainwave states are the most rapid in frequency. 
    Gamma hase long been considered the the brainwave that is able to link and process information from all parts of the brain. 
    It is the frequency that brings with it the ability to process large amounts of information in relatively small amounts of time. 
    Think of generating more Gamma activity as getting a processor upgrade for your brain.

    Unfortunately Gamma brainwaves have received the least attention and research, although more attention is currently being paid to them.
    Having high amounts of Gamma Brainwave activity has been associated with:
    - Having high levels of intelligence
    - Being compassionate
    - Having high amounts of self-control
    - Having greater than average feelings of natural happiness.
    - Increased awareness through your five senses
    - Research has indicated at moments when bursts of precognition or high-level information processing occur, 
    your brainwaves briefly reach the Gamma state.

** IRC
   #emacs ##algorithms ##puzzles #gcj #hackerrank  
   if using weechat `/set irc.server.freenode.autojoin "##algorithms #emacs #gcj"`
   but usually use emacs's irc erc

** The Role of a Teacher (supervised learning)
   The purpose of a teacher is to raise the *right* questions for the student. 
   The role of a student is to seek answers.
   A question needs to be answered.
   Any question creates an empty space in the mind of the student that needs to be filled by answers.


* Knowledge 
  (P) Any knowledge by definition is true otherwise it would be some kind of misinformation.

** What is an Automaton?
   An automaton is a self-operating machine, or a machine or control mechanism designed to automatically 
   follow a predetermined sequence of operations, or respond to predetermined instructions.

** Whats the difference between Automaton and automata?

** What is Finite Automaton?
   - A Formal System
   - Remembers only a finite amount of infromation.
   - Information represented by its state.
   - State changes in response to its inputs.
   - Rules that tell how the state changes in response to inputs are called 
   transitions. 
** Whats the importance of Finite Automata?
   - Used for boh design and verification of circuits and communication protocols
   - Used for many text-processing applications.
   - An important component of compilers.
   - Describes simple patterns of events, etc.

** What is a language of an Automaton?
   - The set of strings accepted by an automaton A is the langauge of A.
   - Denoted L(A).
   - Different sets of final states implies different languages got inserted into the Automaton.
   - Example: As designed, L(Tennis) = strings that determine the winner.

** What is an alphabet?
   An alphabet is any finite set of symbols.



** How can a computer program(finite automata) learn from experiance?
   A computer program is said to learn from experience E with respect
   to some class of tasks T and performance measure P, if its performance at tasks in
   T, as measured by P, improves with experience E.

   (i) A computer program that learns to play checkers might improve
   its performance as measured by its abiliry to win at the class of tasks involving
   playing checkers games, through experience obtained by playing games against
   itself.

   A checkers learning problem:
   - Task T: playing checkers
   - Performance measure P: percent of games won in the world tournament
   - Training experience E: games played against itself
     In order to complete the design of the learning system, we must now choose
     1. the exact type of knowledge to be,learned
     2. a representation for this target knowledge
     3. a learning mechanism


** How to design a machine learning system?
   (idea) if we apply genetic algorithms on these design choices, programs create other programs?
*** Choosing the training experiance: 
    1. Does the training experience provides direct or indirect feedback regarding the choices
    made by the performance system?
    For example, in learning to play checkers, the system might learn from direct training 
    examples consisting of individual checkers board states and the correct move for each. 
    Alternatively, it might have available only indirect information consisting of the move 
    sequences and final outcomes of various games played. In this later case, information 
    about the correctness of specific moves early in the game must be inferred indirectly 
    from the fact that the game was eventually won or lost. Here the learner faces an additional
    problem of credit assignment, or determining the degree to which each move in
    the sequence deserves credit or blame for the final outcome. Credit assignment can
    be a particularly difficult problem because the game can be lost even when early
    moves are optimal, if these are followed later by poor moves. Hence, learning from
    direct training feedback is typically easier than learning from indirect feedback.

  
    2. To what degree does the learner controls the sequence of training examples?
    
    3. How well it represents the distribution of examples over which the final system 
    performance P must be measured?
    
    Most current theory of machine learning rests on the crucial assumption that the distribution of 
    training examples is identical to the distribution of test examples. 
    Despite our need to make this assumption in order to obtain theoretical results, 
    it is important to keep in mind that this assumption must often be violated in practice.

*** Choosing the Target function
    1. How to determine what type of knowledge will be learned?
    2. How this type of knowledge will be used by the performance program?

       The next design choice is to determine exactly what type of knowledge will be
       learned and how this will be used by the performance program.


    Let us begin with a checkers-playing program that can generate the legal moves from any board
    state. 

    The program needs only to learn how to choose the best move from among these legal moves. 

    This learning task is representative of a large class of tasks for which the legal moves that define 
    some large search space are known a priori, but for which the best search strategy is not known. 
    
    Many optimization problems fall into this class, such as the problems of scheduling 
    and controlling manufacturing processes where the available manufacturing steps are 
    well understood, but the best strategy for sequencing them is not.


    Given this setting where we must learn to choose among the legal moves,
    the most obvious choice for the type of information to be learned is a program,
    or function, that chooses the best move for any given board state. Let us call this
    function ChooseMove and use the notation ChooseMove : B -+ M to indicate
    that this function accepts as input any board from the set of legal board states B
    and produces as output some move from the set of legal moves M. Throughout
    our discussion of machine learning we will find it useful to reduce the problem
    of improving performance P at task T to the problem of learning some particu-
    lar targetfunction such as ChooseMove. The choice of the target function will
    therefore be a key design choice

Although ChooseMove is an obvious choice for the target function in our
example, this function will turn out to be very difficult to learn given the kind of in-
direct training experience available to our system. An alternative target function-
and one that will turn out to be easier to learn in this setting-is an evaluation
function that assigns a numerical score to any given board state. Let us call this
target function V and again use the notation V : B + 8 to denote that V maps
any legal board state from the set B to some real value (we use 8 to denote the set
of real numbers). We intend for this target function V to assign higher scores to
better board states. If the system can successfully learn such a target function V ,
then it can easily use it to select the best move from any current board position.
This can be accomplished by generating the successor board state produced by
every legal move, then using V to choose the best successor state and therefore
the best legal move.
What exactly should be the value of the target function V for any given
board state? Of course any evaluation function that assigns higher scores to better
board states will do. Nevertheless, we will find it useful to define one particular
target function V among the many that produce optimal play. As we shall see,
this will make it easier to design a training algorithm. Let us therefore define the
target value V ( b ) for an arbitrary board state b in B , as follows:
1. if b is a final board state that is won, then V ( b ) = 100
2. if b is a final board state that is lost, then V ( b ) = -100
3. if b is a final board state that is drawn, then V ( b ) = 04. if b is a not a final state in the game, then V(b) = V(bl), where b' is the best
final board state that can be achieved starting from b and playing optimally
until the end of the game (assuming the opponent plays optimally, as well).
While this recursive definition specifies a value of V(b) for every board
state b, this definition is not usable by our checkers player because it is not
efficiently computable. Except for the trivial cases (cases 1-3) in which the game
has already ended, determining the value of V(b) for a particular board state
requires (case 4) searching ahead for the optimal line of play, all the way to
the end of the game! Because this definition is not efficiently computable by our
checkers playing program, we say that it is a nonoperational definition. The goal
of learning in this case is to discover an operational description of V ; that is, a
description that can be used by the checkers-playing program to evaluate states
and select moves within realistic time bounds.
Thus, we have reduced the learning task in this case to the problem of
discovering an operational description of the ideal targetfunction V. It may be
very difficult in general to learn such an operational form of V perfectly. In fact,
we often expect learning algorithms to acquire only some approximation to the
target function, and for this reason the process of learning the target function
is often called function approximation. In the current discussion we will use the
symbol ? to refer to the function that is actually learned by our program, to
distinguish it from the ideal target function V.

*** Choosing a Representation for the Target Function
*** Choosing a Function Approximation Algorithm


** What are Karp's 21 NP-complete problems?
** What are Sudoku solving algorithms?
** How to visualize Eleven Dimensions?
** What is Donald Knuth's Dancing Links?
   In computer science, dancing links is the technique suggested by Donald Knuth to efficiently implement his Algorithm X.

** What is Donad Knuth's Algorithm X?
   Algorithm X is a recursive, nondeterministic, depth-first, backtracking algorithm that finds all solutions to the exact cover problem. 
   Some of the better-known exact cover problems include tiling, the n queens problem, and Sudoku.

** What AI is about?
   AI is about Algorithms enabled by constrains, exposed by representations, 
   that support the making of Models that facilitate an understanding of 
   thinking, preception, and actions.

** What are the Greek Letters?
   1. Αα (alpha)
   2. Ββ (beta)
   3. Γγ (gamma)
   4. Δδ (delta)
   5. Εε (epsilon)
   6. Ϝϝ (digamma)
   7. Ζζ (zeta)
   8. Ηη (eta)
   9. Θθ (theta)
   10. Ιι (iota)
   11. Κκ (kappa)
   12. Λλ (lambda)
   13. Μμ (mu)
   14. Νν (nu)
   15. Ξξ (xi)
   16. Οο (omicron)
   17. Ππ (pi)
   18. Ρρ (rho)
   19. Σσς (sigma)
   20. Ττ (tau)
   21. Υυ (upsilon)
   22. Φφ (phi)
   23. Χχ (chi)
   24. Ψψ (psi)
   25. Ωω (omega)

** What is Declarative Kknowledge?
** What is Imperative Kknowledge?
** What are Turing's 6 primative instructions?
   (P) Alan Turing said there are only 6 primative instructions needed to create any program.

** What is Memoization?
   - Memoization is a very common techqiune, we use memoization to solve a lot of problems.
   - In simple terms, we are just remmbering what we did before and just look it up.
   - In summary,it is a fancy way to say we are going to use Table lookup.

** When to use Memoization?
   Thus in a situation where you remmber what the answer was and rather than recalculating it again, we just look it up.
   The concept of memoization is at the heart of dynamic programming.
   - References  
     (r) MIT - Introduction to Computer Science and Programming (Python) ® vampiri6ka/HQ     

** What is Dynamic Programming?
** What are Prime Numbers?                                :zpd:number_theory:
   (p) somthing is a predicate
   (i) somthing is impelied
   (q) a question
** What is Depth First Search?
  
   #+BEGIN_SRC C
     // void dfs(int a) // dfs on node a
     void hello() 
     {
       int x =  1 + 2; 
       printf("%i", x ); 
       // printf("hello world");
     }
     hello();
   #+END_SRC

   #+RESULTS:
   : 3

   - Refernces:
     - icpc.pdf page 10 of 78 
     - cp1.pdf page 70 of 152

** What is Topological Sorting?
   Is a type of Depth First Search, 

  
   
   ---------

** What is Turing Complete?
   - In computability theory, a system of data-manipulation rules (such as a computer's instruction set, 
   a programming language, or a cellular automaton) is said to be Turing complete or computationally 
   universal if it can be used to simulate any single-taped Turing machine. 
   The concept is named after English mathematician Alan Turing. A classic example is lambda calculus.
   
** What is Turing Equivalence?

** What is Python?
   - interperted langauge, (can also complie it)
   - a variable is a name of an objective
   - an assigment binds a name to an object.
   - python forces indentation thus that the visual structure actually matchs the semantic structure. 

** What is Machine Learning? 
   - Machine Learning is a class of algorithms which is data-driven, 
   i.e. unlike "normal" algorithms it is the data that "tells" what the "good answer" is
   - Example: a hypothetical non-machine learning algorithm for face detection in images 
   would try to define what a face is (round skin-like-colored disk, with dark area where 
   you expect the eyes etc). A machine learning algorithm would not have such coded 
   definition, but would "learn-by-examples": you'll show several images of faces and 
   not-faces and a good algorithm will eventually learn and be able to predict whether or not an unseen image is a face. 
 
   - Machine Learning Types:
   Supervised: All data is labeled and the algorithms learn to predict the output from the input data.
   Unsupervised: All data is unlabeled and the algorithms learn to inherent structure from the input data.
   Semi-supervised: Some data is labeled but most of it is unlabeled and a mixture of supervised and unsupervised techniques can be used. 

** What is Supervised Learning?
   - Supervised learning is when the data you feed your algorithm is "tagged" to help your logic make decisions.
   - Example: Bayes spam filtering, where you have to flag an item as spam to refine the results.
   - Applications in which the training data comprises examples of the input vectors along with their 
   corresponding target vectors are known as supervised learning problems.
   - Approaches to supervised learning include:
     - Classification(1R, Naive Bayes, Decision tree learning algorithm such as ID3 CART and so on)
     - Numeric Value Prediction
   - Supervised learning: It is the machine learning task of inferring a function from labeled training data.The training data consist of a set of training examples. In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal). A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples.
   The computer is presented with example inputs and their desired outputs, given by a "teacher", and the goal is to learn a general rule that maps inputs to outputs.Specifically, a supervised learning algorithm takes a known set of input data and known responses to the data (output), and trains a model to generate reasonable predictions for the response to new data.
   - The classification and regression supervised learning problems.
** When to use supervised learning?

** What is Unsupervised Learning?
   - You should use unsupervised learning methods when you need a large amount of data to train your models, and the willingness and ability to experiment and explore, and of course a challenge that isn’t well solved via more-established methods.With unsupervised learning it is possible to learn larger and more complex models than with supervised learning.Here is a good example on it
   - Unsupervised learning are types of algorithms that try to find correlations without any external inputs other than the raw data.
   - Example: datamining clustering algorithms.
   - In other pattern recognition problems, the training data consists of a set of input vectors x without any corresponding target values.
     The goal in such unsupervised learning problems may be to discover groups of similar examples within the data, where it is called clustering
   - Approaches to unsupervised learning include:
     - Clustering(K-mean,hierarchical clustering)
     - Association Rule Learning
   - Unsupervised learning: It is learning without a teacher. 
   One basic thing that you might want to do with data is to visualize it. It is the machine learning task of inferring a function to describe hidden structure from unlabeled data. Since the examples given to the learner are unlabeled, there is no error or reward signal to evaluate a potential solution. This distinguishes unsupervised learning from supervised learning. Unsupervised learning uses procedures that attempt to find natural partitions of patterns.
   - The clustering and association unsupervised learning problems.
** When to use unsupervised learning?

** What is DeepCoder?
   * We develop a first line of attack for solving programming competition-style prob-
   lems from input-output examples using deep learning. The approach is to train a
   neural network to predict properties of the program that generated the outputs from
   the inputs. We use the neural network’s predictions to augment search techniques
   from the programming languages community, including enumerative search and
   an SMT-based solver. Empirically, we show that our approach leads to an order
   of magnitude speedup over the strong non-augmented baselines and a Recurrent
   Neural Network approach, and that we are able to solve problems of difficulty
   comparable to the simplest problems on programming competition websites.

** What is Semi-supervised Learning?
   - A problem that sits in between supervised and unsupervised learning called semi-supervised learning.
   - Problems where you have a large amount of input data (X) and only some of the data is labeled (Y) 
   are called semi-supervised learning problems.
   - Semi-supervised learning problems sit in between both supervised and unsupervised learning.
   - A good example is a photo archive where only some of the images are labeled, (e.g. dog, cat, person) and the majority are unlabeled.
   - Many real world machine learning problems fall into this area. This is because it can be expensive or 
     time-consuming to label data as it may require access to domain experts. Whereas unlabeled data is cheap and easy to collect and store.
   - You can use unsupervised learning techniques to discover and learn the structure in the input variables.
   - You can also use supervised learning techniques to make best guess predictions for the unlabeled data, 
     feed that data back into the supervised learning algorithm as training data and use the model to make predictions on new unseen data.
** What is active learning?
** What is PageRank?
** When to use Octave?
   (P) Always use octave for prototyping machine learning algorithms, and only after that migrate it in another language.
   (P) if we use octave as our programming enviroment for machine learning, will learn much more faster than
   using python, C++, or Java, as it is just functions.

** What is the Cocktail Party Problem?
   - in only one line of code! in octave.

** What is Linear Regression?
   - Regression means " انحسار"

   In statistics, linear regression is an approach for modeling the relationship between a scalar 
   dependent variable y and one or more explanatory variables (or independent variables) denoted X. 
 
   The case of one explanatory variable is called simple linear regression. 
   For more than one explanatory variable, the process is called multiple linear regression. 
   (This term is distinct from multivariate linear regression, where multiple correlated dependent 
   variables are predicted, rather than a single scalar variable.)

** What is Linear Regression with one variable (Univariate Linear Regression)?
*** Model Representation
    We have data that is plotted on a graph.
    This is supervised learning as we are given the "right answer" for each example in the data.
    This is a type of a Regression problem where we predict real-valued output. 

    m = Number of training examples
    x's = "input" variable/ features
    y's = "output" variable / "target" variable

    (          training set       )
    			\Downarrow     
    (        learning algorithms  )
    			\Downarrow     
    	size of house \rightarrow  h   \rightarrow estimated price



*** Cost Function
    \ \odot = \theta + \Theta1 x 
**** Cost Function Intuition

*** Gardient Descent
**** Gardient Descent Intuition
**** Gardient Descent for Linear Regression
     
** What is Focused Crawling?
   A focused crawler is a web crawler that collects Web pages that satisfy some specific property, 
   by carefully prioritizing the crawl frontier and managing the hyperlink exploration process. 
   Some predicates may be based on simple, deterministic and surface properties. 
   For example, a crawler's mission may be to crawl pages from only the .jp domain. 
   Other predicates may be softer or comparative, e.g., "crawl pages with large PageRank", 
   or "crawl pages about baseball". An important page property pertains to topics, leading to 
   topical crawlers. For example, a topical crawler may be deployed to collect pages about solar power, 
   or swine flu, while minimizing resources spent fetching pages on other topics. Crawl frontier 
   management may not be the only device used by focused crawlers; they may use a Web directory, 
   a Web text index, backlinks, or any other Web artifact.

** What is Radix Sort?
   http://www.geeksforgeeks.org/radix-sort/ 

** What is an Order Statistic Tree?
** What is a B-tree?
** What is Binary Search Tree (BST)?
   
** References  
   #+begin_src sh :results output :exports results
     echo "Directory structure:" 
     tree /home/zotherstupidguy/Study/3.Sources/Machine\ Learning\ -\ Stanford 
   #+end_src

   #+RESULTS:
   #+begin_example
   #+end_example

*** TODO TTC VIDEO - The Art and Craft of Mathematical Problem Solving :problemsolving:
    :PROPERTIES:
    :ZPT:      0
    :DESCRIPTION: This is an online course blahblah
    :CATEGORY: problemsolving
    :CUSTOM_ID: an-extra-special-headline
    :END:
    * Diference between Problem and Exercise :: Scope doesn't work as expected, and messes everything up
         when loops mix variables up in recursive functions.
         - Namespaces :: You wish. 
         - Header Files :: Nope.
         information about the source here, author, edition, date, who is using it in univ cources, etc.

*** TODO Cracking the Coding Interview                   :book:zpd:interview:
    :PROPERTIES:
    :BIB_AUTHOR: Walter Evensong
    :BIB_TITLE: Mysteries of the Amazon
    :BIB_PAGES: 1234
    :BIB_PUBLISHER: Humbug University Press
    :END:
****** TODO Chapter1 
******* TODO name of the heading in the chapter
******* TODO name of the heading in the chapter
****** DONE sfsf
****** sfsfsfsf

*** TODO arabic competitive programming     :youtube:competitive_programming:
    - name of each eposide extracted via a script from Emacs and into a list here

*** TODO Introduction to the Theory of Computation - 3rd - Spiser
    :PROPERTIES:
    :BIB_AUTHOR: Walter Evensong
    :BIB_TITLE: Mysteries of the Amazon
    :BIB_PAGES: 1234
    :BIB_PUBLISHER: Humbug University Press
    :END:
    - name of each chapter a list here

*** TODO hackerrank                         :youtube:competitive_programming:
*** TODO codejam                            :youtube:competitive_programming:
*** TODO codemasrytube                      :youtube:competitive_programming:
*** TODO mycodeschool                       :youtube:competitive_programming:
*** TODO saurabhschool                      :youtube:competitive_programming:
*** TODO codinginterviewhub                 :youtube:competitive_programming:
*** TODO conor                              :youtube:competitive_programming:
*** TODO geeksforgeeks                      :youtube:competitive_programming:
*** TODO Elementry Number Theory - 6th Edition - Kenneth H. Rosen 
    [[file:3.Sources/NumberTheory/Books/Elementary%20Number%20Theory%20-%206th%20Edition%20-%20Kenneth%20H.%20Rosen.pdf][file:3.Sources/NumberTheory/Books/Elementary Number Theory - 6th Edition - Kenneth H. Rosen.pdf]]  



    -----

*** TODO MIT - Introduction to Computer Science and Programming (Python) ® vampiri6ka/HQ [3/6]    
**** DONE 01-Lecture 01_ Introduction to 6.00
     CLOSED: [2017-02-24 Fri 17:37]
**** DONE 02-Lecture 
     CLOSED: [2017-02-24 Fri 17:37]
**** DONE 03-Lecture 
     CLOSED: [2017-02-25 Sat 05:45]
**** TODO 04-Lecture 
**** TODO 31-Lecture 21_ Using Graphs to Model Problems, Part 1

**** TODO 32-Lecture 22_ Using Graphs to Model Problems, Part 2

*** TODO Machine Learning - Stanford
**** TODO 1
**** TODO 2


   /home/zotherstupidguy/Study/3.Sources/Machine Learning - Stanford
   ├── 01.2-V2-Introduction-WhatIsMachineLearning.mp4
   ├── 01.3-V2-Introduction-SupervisedLearning.mp4
   ├── 01.4-V2-Introduction-UnsupervisedLearning.mp4
   ├── 02.1-V2-LinearRegressionWithOneVariable-ModelRepresentation.mp4
   ├── 02.2-V2-LinearRegressionWithOneVariable-CostFunction.mp4
   ├── 02.3-V2-LinearRegressionWithOneVariable-CostFunctionIntuitionI.mp4
   ├── 02.4-V2-LinearRegressionWithOneVariable-CostFunctionIntuitionII.mp4
   ├── 02.5-V2-LinearRegressionWithOneVariable-GradientDescent.mp4
   ├── 02.6-V2-LinearRegressionWithOneVariable-GradientDescentIntuition.mp4
   ├── 02.7-V2-LinearRegressionWithOneVariable-GradientDescentForLinearRegression.mp4
   ├── 02.8-V2-What'sNext.mp4
   ├── 03.1-V2-LinearAlgebraReview(Optional)-MatricesAndVectors.mp4
   ├── 03.2-V2-LinearAlgebraReview(Optional)-AdditionAndScalarMultiplication.mp4
   ├── 03.3-V2-LinearAlgebraReview(Optional)-MatrixVectorMultiplication.mp4
   ├── 03.4-V2-LinearAlgebraReview(Optional)-MatrixMatrixMultiplication.mp4
   ├── 03.5-V2-LinearAlgebraReview(Optional)-MatrixMultiplicationProperties.mp4
   ├── 03.6-V2-LinearAlgebraReview(Optional)-InverseAndTranspose.mp4
   ├── 04.1-LinearRegressionWithMultipleVariables-MultipleFeatures.mp4
   ├── 04.2-LinearRegressionWithMultipleVariables-GradientDescentForMultipleVariables.mp4
   ├── 04.3-LinearRegressionWithMultipleVariables-GradientDescentInPracticeIFeatureScaling.mp4
   ├── 04.4-LinearRegressionWithMultipleVariables-GradientDescentInPracticeIILearningRate.mp4
   ├── 04.5-LinearRegressionWithMultipleVariables-FeaturesAndPolynomialRegression.mp4
   ├── 04.6-V2-LinearRegressionWithMultipleVariables-NormalEquation.mp4
   ├── 04.7-LinearRegressionWithMultipleVariables-NormalEquationNonInvertibility(Optional).mp4
   ├── 05.1-OctaveTutorial-BasicOperations.mp4
   ├── 05.2-OctaveTutorial-MovingDataAround.mp4
   ├── 05.3-OctaveTutorial-ComputingOnData.mp4
   ├── 05.4-OctaveTutorial-PlottingData.mp4
   ├── 05.5-OctaveTutorial-ForWhileIfStatementsAndFunctions.mp4
   ├── 05.6-OctaveTutorial-Vectorization.mp4
   ├── 05.7-OctaveTutorial-WorkingOnAndSubmittingProgrammingExercises.mp4
   ├── 06.1-LogisticRegression-Classification.mp4
   ├── 06.2-LogisticRegression-HypothesisRepresentation.mp4
   ├── 06.3-LogisticRegression-DecisionBoundary.mp4
   ├── 06.4-LogisticRegression-CostFunction.mp4
   ├── 06.5-LogisticRegression-SimplifiedCostFunctionAndGradientDescent.mp4
   ├── 06.6-LogisticRegression-AdvancedOptimization.mp4
   ├── 06.7-LogisticRegression-MultiClassClassificationOneVsAll.mp4
   ├── 07.1-Regularization-TheProblemOfOverfitting.mp4
   ├── 07.2-Regularization-CostFunction.mp4
   ├── 07.3-Regularization-RegularizedLinearRegression.mp4
   ├── 07.4-Regularization-RegularizedLogisticRegression.mp4
   ├── 08.1-NeuralNetworksRepresentation-NonLinearHypotheses.mp4
   ├── 08.2-NeuralNetworksRepresentation-NeuronsAndTheBrain.mp4
   ├── 08.3-NeuralNetworksRepresentation-ModelRepresentationI.mp4
   ├── 08.4-NeuralNetworksRepresentation-ModelRepresentationII.mp4
   ├── 08.5-NeuralNetworksRepresentation-ExamplesAndIntuitionsI.mp4
   ├── 08.6-NeuralNetworksRepresentation-ExamplesAndIntuitionsII.mp4
   ├── 08.7-NeuralNetworksRepresentation-MultiClassClassification.mp4
   ├── 09.1-NeuralNetworksLearning-CostFunction.mp4
   ├── 09.2-NeuralNetworksLearning-BackpropagationAlgorithm.mp4
   ├── 09.3-NeuralNetworksLearning-BackpropagationIntuition.mp4
   ├── 09.3-NeuralNetworksLearning-ImplementationNoteUnrollingParameters.mp4
   ├── 09.4-NeuralNetworksLearning-GradientChecking.mp4
   ├── 09.5-NeuralNetworksLearning-RandomInitialization.mp4
   ├── 09.7-NeuralNetworksLearning-PuttingItTogether.mp4
   ├── 09.8-NeuralNetworksLearning-AutonomousDrivingExample.mp4
   ├── 10.1-AdviceForApplyingMachineLearning-DecidingWhatToTryNext.mp4
   ├── 10.2-AdviceForApplyingMachineLearning-EvaluatingAHypothesis.mp4
   ├── 10.3-AdviceForApplyingMachineLearning-ModelSelectionAndTrainValidationTestSets.mp4
   ├── 10.4-AdviceForApplyingMachineLearning-DiagnosingBiasVsVariance.mp4
   ├── 10.5-AdviceForApplyingMachineLearning-RegularizationAndBiasVariance.mp4
   ├── 10.6-AdviceForApplyingMachineLearning-LearningCurves.mp4
   ├── 10.7-AdviceForApplyingMachineLearning-DecidingWhatToDoNextRevisited.mp4
   ├── 11.1-MachineLearningSystemDesign-PrioritizingWhatToWorkOn.mp4
   ├── 11.2-MachineLearningSystemDesign-ErrorAnalysis.mp4
   ├── 11.3-MachineLearningSystemDesign-ErrorMetricsForSkewedClasses.mp4
   ├── 11.4-MachineLearningSystemDesign-TradingOffPrecisionAndRecall.mp4
   ├── 11.5-MachineLearningSystemDesign-DataForMachineLearning.mp4
   ├── 12.1-SupportVectorMachines-OptimizationObjective.mp4
   ├── 12.2-SupportVectorMachines-LargeMarginIntuition.mp4
   ├── 12.3-SupportVectorMachines-MathematicsBehindLargeMarginClassificationOptional.mp4
   ├── 12.4-SupportVectorMachines-KernelsI.mp4
   ├── 12.5-SupportVectorMachines-KernelsII.mp4
   ├── 12.6-SupportVectorMachines-UsingAnSVM.mp4
   ├── 14.1-Clustering-UnsupervisedLearningIntroduction.mp4
   ├── 14.2-Clustering-KMeansAlgorithm.mp4
   ├── 14.3-Clustering-OptimizationObjective.mp4
   ├── 14.4-Clustering-RandomInitialization.mp4
   ├── 14.5-Clustering-ChoosingTheNumberOfClusters.mp4
   ├── 15.1-DimensionalityReduction-MotivationIDataCompression.mp4
   ├── 15.2-DimensionalityReduction-MotivationIIVisualization.mp4
   ├── 15.3-DimensionalityReduction-PrincipalComponentAnalysisProblemFormulation.mp4
   ├── 15.4-DimensionalityReduction-PrincipalComponentAnalysisAlgorithm.mp4
   ├── 15.5-DimensionalityReduction-ChoosingTheNumberOfPrincipalComponents.mp4
   ├── 15.6-DimensionalityReduction-ReconstructionFromCompressedRepresentation.mp4
   ├── 15.7-DimensionalityReduction-AdviceForApplyingPCA.mp4
   ├── 16.1-AnomalyDetection-ProblemMotivation-V1.mp4
   ├── 16.2-AnomalyDetection-GaussianDistribution.mp4
   ├── 16.3-AnomalyDetection-Algorithm.mp4
   ├── 16.4-AnomalyDetection-DevelopingAndEvaluatingAnAnomalyDetectionSystem.mp4
   ├── 16.5-AnomalyDetection-AnomalyDetectionVsSupervisedLearning-V1.mp4
   ├── 16.6-AnomalyDetection-ChoosingWhatFeaturesToUse.mp4
   ├── 16.7-AnomalyDetection-MultivariateGaussianDistribution-OPTIONAL.mp4
   ├── 16.8-AnomalyDetection-AnomalyDetectionUsingTheMultivariateGaussianDistribution-OPTIONAL.mp4
   ├── 17.1-RecommenderSystems-ProblemFormulation.mp4
   ├── 17.2-RecommenderSystems-ContentBasedRecommendations.mp4
   ├── 17.3-RecommenderSystems-CollaborativeFiltering-V1.mp4
   ├── 17.4-RecommenderSystems-CollaborativeFilteringAlgorithm.mp4
   ├── 17.5-RecommenderSystems-VectorizationLowRankMatrixFactorization.mp4
   ├── 17.6-RecommenderSystems-ImplementationalDetailMeanNormalization.mp4
   ├── 18.1-LargeScaleMachineLearning-LearningWithLargeDatasets.mp4
   ├── 18.2-LargeScaleMachineLearning-StochasticGradientDescent.mp4
   ├── 18.3-LargeScaleMachineLearning-MiniBatchGradientDescent.mp4
   ├── 18.4-LargeScaleMachineLearning-StochasticGradientDescentConvergence.mp4
   ├── 18.5-LargeScaleMachineLearning-OnlineLearning.mp4
   ├── 18.6-LargeScaleMachineLearning-MapReduceAndDataParallelism.mp4
   ├── 19.1-ApplicationExamplePhotoOCR-ProblemDescriptionAndPipeline.mp4
   ├── 19.2-ApplicationExamplePhotoOCR-SlidingWindows.mp4
   ├── 19.3-ApplicationExamplePhotoOCR-GettingLotsOfDataArtificialDataSynthesis.mp4
   ├── 19.4-ApplicationExamplePhotoOCR-CeilingAnalysisWhatPartOfThePipelineToWorkOnNext.mp4
   ├── 20.1-Conclusion-SummaryAndThankYou.mp4

*** TODO MIT 6.042J Mathematics for Computer Science, Spring 2015
    source: https://www.youtube.com/playlist?list=PLUl4u3cNGP60UlabZBeeqOuoLuj_KNphQ

*** TODO Machine Learning, 1997 by Tom M. Mitchell
**** TODO Introduction
**** TODO Concept Learning and the General-to-Specific Ordering 
**** TODO Decision Tree Learning
**** TODO Artificial Neural Networks 
**** TODO Evaluating Hypotheses 
**** TODO Bayesian Learning  
**** TODO Computational Learning Theory 
**** TODO Instance-Based Learning 
**** TODO Genetic Algorithms 
**** TODO Learning Sets of Rules 
**** TODO Analytical Learning 
**** TODO Combining Inductive And Analytical Learning 
**** TODO Reinforcement Learning

* Problems
** Birthday Cake Candles  
   :PROPERTIES:   
   :SCHEDULED: <2017-02-19 Sun +2d/4d>
   The repeat specification, .+2d/4d means:
   Repeat as frequently as every two days, but
   Never less frequently than every four days, and
   When completed, start counting again from today. 
   :DESCRIPTION: hackerrank problem, found in rookierank2 contest, its about dupilcates in an array
   :Difficulty: easy  
   :CATEGORY: search algorithms 
   :Source:      https://www.hackerrank.com/contests/rookierank/challenges/birthday-cake-candles
   :ZPT:      1
   :END:
** :problem:
   -  Colleen is turning  \(n\)  years old!                        
   - She has  \(n\)  candles of various heights on her cake, 
   - Candle \(i\) has height \(heighti\) . Because the taller candles tower over the shorter ones, Colleen can only blow out the tallest candles.
   -  Given the  for each individual candle, find and print the number of candles she can successfully blow out.
*** :input: 
    - The first line contains a single integer, , denoting the number of candles on the cake. 
    - The second line contains  space-separated integers, where each integer  describes the height of candle .
*** :constraints:
    none
*** :output: 
    - Print the number of candles Colleen blows out on a new line.
*** :explanation:
    - 1..
    - 2.. 
** :solution:
*** :questions:
    none
*** :predicates:   
    - the brute force solution gives O(N^2) via comparing each of two strings. 
    - A common technique is the trade-off between time and space. 
    - We want to make the algorithm faster, we can think of how to use more memory to solve the problem. .
    - The keyphrase “find duplicate”, is translated to "use a hash set" immediately,  as hash is the most common technique to detect duplicates. 
*** :implications:
    - If we store every element into a hash set, we can make it O(N) for both time and space complexity.
    #+BEGIN_SRC ruby
      def input
        p "love emacs, because emacs is a philosphy of how yo all dealing with computer..."
      end
      def output
      end       
      input
    #+END_SRC

    #+RESULTS: 
    : love emacs, because emacs is a philosphy of how yo all dealing with computer

** References       
   - source: https://www.hackerrank.com/contests/rookierank/challenges/birthday-cake-candles
   - ref: http://blog.gainlo.co/index.php/2016/05/10/duplicate-elements-of-an-array/

   ----- 

** TODO Somthing 
   :PROPERTIES:   
   :SCHEDULED: <2017-02-19 Sun +2d/4d>
   :DESCRIPTON: hackerrank problem, found in....
   :Difficulty: easy
   :CATEGORY: none
   :Source:   none
   :ZPT:      1
   :END:
*** :problem:
    -  something
**** :input: 
     - none 
**** :constraints:
     - none
**** :output: 
     - none
**** :explanation:
     - none
*** :solution:
**** :questions:
     - none
**** :predicates:   
     - none
**** :implications:
     - none
       #+BEGIN_SRC ruby
       #+END_SRC
       #+BEGIN_SRC C 
       #+END_SRC
*** References       
    -  none

      -----

** TODO Journey to the moon                              :graphtheory:medium: 
   :PROPERTIES:   
   :SCHEDULED: <2017-03-13 Mon +2d/4d>
   :DESCRIPTION: hackerrank problem, found in rookierank2 contest, its about dupilcates in an array
   :Difficulty: medium
   :CATEGORY: graphtheory
   :Source:   https://www.hackerrank.com/challenges/journey-to-the-moon
   :LAST_REPEAT: [2017-02-24 Fri 12:37]
   :END:
   - State "DONE"       from "TODO"       [2017-02-24 Fri 12:37]
   - State "DONE"       from "TODO"       [2017-02-24 Fri 12:36]
   - State "DONE"       from "TODO"       [2017-02-24 Fri 12:36]
   - dfasf
   asdffasf
   asdfasdf
   asdfasfafasf
   asdfasfa

** Battlecode
   MIT AI game #battlecode@freenode.net

** ProblemName KnightL on a Chessboard
** ProblemStatment 
   is a chess piece that moves in an L shape. We define the possible moves of  as any movement from some position  to some  satisfying either of the following:
** Input Format 
** Constraints
** Out Format
** Solution 
** Theatre Square                                :website:codeforces:contest:

   source: http://codeforces.com/contest/1/problem/A
   ----- 


  
   keep log of all the interviews I made and schedules for upcoming interviews, as well as info for mastering the
   art of interviews. 
  
   Some people make multiple interviews with fake names, imporsnating someone who doens't
   have a public profile photo on twitter and github, they require a fake skypename for that! You are too lazy for this :))

** References       
   - not related to the problem but good to notice https://en.wikipedia.org/wiki/Knight's_tour
     

   ----- 

   
* Distractions 
  write down distractions here to focus on task at hand, good for the focus muscle, 
  watch https://www.youtube.com/watch?v=H0k0TQfZGSc
** TODO Index CodeJam website and collection all their problem sets and Answers!.
** TODO Org-mode shortcuts for SQ3R
   - If I press space-q then I get (Q) with color red
   - If I press space-p then I get (P) with color blue
   - If I press space-p then I get (I) with color green
   - If I press space-p then I get (I) with color yellow
** TODO how to get all the file names from a folder and write them in a ** Reference TODO
** TODO how to do references between the * Knoweldge and ** References  
** DONE ban facebook
   CLOSED: [2017-03-01 Wed 01:11]
   /etc/hosts
   0.0.0.1         facebook.com    
   0.0.0.1         www.facebook.com

** Hackertyper for reviewing practiced algorithms
  I should use hackertyper to review practiced algorithms,
  ref: http://www.hackertyper.com/
  
** How to use emacs in my life?
   So the idea is that I while I want to code, I code in C or ruby file using its respective emacs-mode and its capabilities, but when i want to take notes and log it into my blog, 
   I use org-capture. as I am very neat and I know what kind of stuff I add into my single-page blog, I have created many templates to my various data contents, 
   example: if i am solving a hackerrank problem and i got it to pass, and now I want to add it to my blog, I just press C-cc followed by h or similar to start editing the hackerrank template, C-c C-c to finish 
   and have it saved to the end of my blog with all the correct tags that gets viewed via emacs agenda later on. 

   This is so powerful that I can create many powerful org-capture templates and save it in my .emacs and keep enhancing them to reflect my level of performance in study, practice and work. 

   *use C-c \* to search for zpd0, zpd1, zpd2 tags and find what you are trying to do that day, and C-c C-c to choose the tags
   *use space-p* to add new empty line in org-mode
** PracticeTips:
   - Whenever you solve some questions, try to ask yourself what if we *expand the question to a larger scale!*
   - *Revisit old problems* and think about new techqinues, better ways, different contexts, different constrains, etc.  
   - every solution is a finite state automata
**  use inf-ruby more often please
   ;; inf-ruby
   ;;Use C-c C-s to launch the inf-ruby process.
   ;;Use C-x o to switch to the inf-ruby pane and try running some random ruby snippets as you normally would from IRB or pry.
   ;;Go back to your Ruby buffer, select (by highlighting) a chunk of code, and use C-c C-r to push that Ruby code into the IRB session.
   ;;For example, try defining a class in your Ruby buffer, select the whole buffer, run C-c C-r, then swap over to the inf-ruby buffer and instantiate an instance of your class. Pretty cool!
   ;;Alternatively, use C-c M-r to run a selected chunk of code and automatically go to the ruby buffer
   ;;Finally, use helm-M-x (which we bound earlier to the default M-x keybinding) to search for âruby sendâ and see what other default bindings inf-ruby gives us.
   ;;If you do a lot of work in Rails or Sinatra, check out the commands inf-ruby-console-rails and inf-ruby-console-racksh. Using these commands inf-ruby can start a console session in the environment of your web project.
   (autoload 'inf-ruby-minor-mode "inf-

** TODO
   - create templates for hackerrank problems, store in zotherstupidguy.github.io/org/templates/hackerrank.text
   - codeforces problems, store in zotherstupidguy.github.io/org/templates/codeforces.text
   - experiment with org-mode agenda to view my headings based on their tags? or a smiliar functionality from somthing else maybe! 
   - use org-capture for saving common algorithms in C. eg. sorting.c shortestpath.c, etc.
   - find the ability to query my huge org file.  
   - on emacs open, make sure it opens scratch and also opens index.org and make index.org the active buffer to easily edit.
   - org-capture template for Questions, Predicates, and Implications

** Emacs Agenda :agenda:
   The agenda allows you to create filtered views of the items in your 
   *agenda files*("day-planner" views of your schedule, lists of your todos, and the results of queries (for tags, words, regular expressions, etc.)).

   One use of the agenda is as a day planner system. If you prefer to schedule your tasks and to see a daily agenda of TODOs, you'll probably be pressing C-c a a a lot.
   The agenda can also be used for a powerful GTD system. If you like to filter your "next actions" by context, 
   then you'll probably make frequent use of C-c a t to see a list of all your active TODOs and to filter them by tag/context.
   While the agenda is a powerful task management tool, it is also a fantastic research tool. If you keep a file full of reading notes, 
   for instance, you can use the agenda to locate entries containing a particular word or labeled by a particular tag.

   *Do you want quickly to filter for the item in the agenda view? If so, a tag is probably your best choice.*
   Note, you can add a setting to your .emacs that automatically adds a tag whenever you assign a particular TODO keyword. Type "C-c v org-todo-state-tags-triggers" for more information.
   An excellent way to implement labels and contexts for cross-correlating information is to assign tags to headlines. Org mode has extensive support for tags.

   Every headline can contain a list of tags; they occur at the end of the headline. Tags are normal words containing letters, numbers, ‘_’, and ‘@’. Tags must be preceded and followed by a single colon, e.g., ‘:work:’. Several tags can be specified, as in ‘:work:urgent:’. Tags will by default be in bold face with the same color as the headline.

   Tag inheritance: Tags use the tree structure of the outline
   Setting tags: How to assign tags to a headline
   Tag groups: Use one tag to search for several tags
   Tag searches: Searching for combinations of tags
   ref: http://orgmode.org/guide/Tags.html#Tags
  
** C programs debugging via GDB in Emacs   
   https://kb.iu.edu/d/aqsy
  


** TODO Viewing images inside emacs (org-mode)
